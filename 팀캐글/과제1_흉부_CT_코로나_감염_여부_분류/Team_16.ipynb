{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bb83579-2de1-4894-87b2-d2fbfdbcb1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a2ea47c-3664-488a-b892-1a6e5c1219df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"train.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ba7c1-0393-47ec-89d9-f6f97072773b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4325d39-6344-4116-b343-df51696905ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease                  \n",
      "Hit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease          \n",
      "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
      "Reading package lists... Done                    \n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "python3-opencv is already the newest version (3.2.0+dfsg-4ubuntu0.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 77 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get update && apt-get install -y python3-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f475804-13db-484c-a348-f01580e80a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56ea136a-33db-4aa5-88e1-9ac0251764b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.4 MB 57 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3; python_version >= \"3.8\" in /opt/conda/lib/python3.8/site-packages (from opencv-python) (1.19.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.62\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a86b34a-1e4f-47f6-843b-830dc2a78624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7 MB 15.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2020.5)\n",
      "Requirement already satisfied: numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /opt/conda/lib/python3.8/site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a45c7e-10ca-4fd1-9fd4-6326313a631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, copy, cv2, sys, random\n",
    "# from datetime import datetime, timezone, timedelta\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c255b-b30d-4ffd-a663-bc01a2c37954",
   "metadata": {},
   "source": [
    "## Set Arguments & hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9c4250-2257-404f-941d-58eff1e9eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드(seed) 설정\n",
    "\n",
    "RANDOM_SEED = 2022\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9c63836-0a7a-48f7-a5ea-e16b617fec65",
   "metadata": {},
   "source": [
    "# 데이터 디렉토리 구조\n",
    "\n",
    "data/  \n",
    "  \\_train/  \n",
    "    \\_0.png  \n",
    "    \\_1.png  \n",
    "    \\_...  \n",
    "  \\_test/  \n",
    "    \\_0.png  \n",
    "    \\_1.png  \n",
    "    \\_...  \n",
    "  \\_train.csv  \n",
    "  \\_sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d69a8bc-2e64-4de6-928f-4e16957f6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "### 데이터 디렉토리 설정 ###\n",
    "DATA_DIR= 'data'\n",
    "NUM_CLS = 3\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0005\n",
    "EARLY_STOPPING_PATIENCE = 20\n",
    "INPUT_SHAPE = 128\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44807b0-7788-49ec-aff2-c756e4513c5e",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b81fa5-3756-46aa-b3cb-6f19879aba05",
   "metadata": {},
   "source": [
    "#### Train & Validation Set loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04642777-c2e0-439b-9692-f6c571a86521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, mode, input_shape):\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # Loading dataset\n",
    "        self.db = self.data_loader()\n",
    "        \n",
    "        # Dataset split\n",
    "        if self.mode == 'train':\n",
    "            self.db = self.db[:int(len(self.db) * 0.9)]\n",
    "        elif self.mode == 'val':\n",
    "            self.db = self.db[int(len(self.db) * 0.9):]\n",
    "            self.db.reset_index(inplace=True)\n",
    "        else:\n",
    "            print(f'!!! Invalid split {self.mode}... !!!')\n",
    "            \n",
    "        # Transform function\n",
    "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading ' + self.mode + ' dataset..')\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
    "            sys.exit()\n",
    "        \n",
    "        # (COVID : 1, No : 0)\n",
    "        db = pd.read_csv(os.path.join(self.data_dir, 'train.csv'))\n",
    "        \n",
    "        return db\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = copy.deepcopy(self.db.loc[index])\n",
    "\n",
    "        # Loading image\n",
    "        cvimg = cv2.imread(os.path.join(self.data_dir,'train',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
    "        if not isinstance(cvimg, np.ndarray):\n",
    "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
    "\n",
    "        # Preprocessing images\n",
    "        trans_image = self.transform(Image.fromarray(cvimg))\n",
    "\n",
    "        return trans_image, data['COVID']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b27520-c82c-4ec8-ae0b-119a79167f09",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "685e0b73-f323-40ea-b372-6c1d607618a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class custom_CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(custom_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=25, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=25*29*29, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # (32, 3, 128, 128) -> (32, 8, 62, 62)\n",
    "        x = self.pool(F.relu(self.conv2(x))) # (32, 8, 62, 62) -> (32, 25, 29, 29)\n",
    "        \n",
    "        x = torch.flatten(x,1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        \n",
    "        output = self.softmax(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d056905-1f77-4579-a260-07bb1056f6db",
   "metadata": {},
   "source": [
    "## Utils\n",
    "### EarlyStopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b4c3315-ebca-4e6b-a8f2-1281ccd0bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossEarlyStopper():\n",
    "    \"\"\"Early stopper\n",
    "    \n",
    "    Attributes:\n",
    "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가, 감소 시 0으로 리셋\n",
    "        min_loss (float): 최소 loss\n",
    "        stop (bool): True 일 때 학습 중단\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience: int)-> None:\n",
    "        self.patience = patience\n",
    "\n",
    "        self.patience_counter = 0\n",
    "        self.min_loss = np.Inf\n",
    "        self.stop = False\n",
    "        self.save_model = False\n",
    "\n",
    "    def check_early_stopping(self, loss: float)-> None:\n",
    "        \"\"\"Early stopping 여부 판단\"\"\"  \n",
    "\n",
    "        if self.min_loss == np.Inf:\n",
    "            self.min_loss = loss\n",
    "            return None\n",
    "\n",
    "        elif loss > self.min_loss:\n",
    "            self.patience_counter += 1\n",
    "            msg = f\"Early stopping counter {self.patience_counter}/{self.patience}\"\n",
    "\n",
    "            if self.patience_counter == self.patience:\n",
    "                self.stop = True\n",
    "                \n",
    "        elif loss <= self.min_loss:\n",
    "            self.patience_counter = 0\n",
    "            self.save_model = True\n",
    "            msg = f\"Validation loss decreased {self.min_loss} -> {loss}\"\n",
    "            self.min_loss = loss\n",
    "        \n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaffd8d-b025-42c1-8dd8-69529487389e",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5faaac1b-64c3-4659-82de-d4309502f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    \"\"\" epoch에 대한 학습 및 검증 절차 정의\"\"\"\n",
    "    \n",
    "    def __init__(self, loss_fn, model, device, metric_fn, optimizer=None, scheduler=None):\n",
    "        \"\"\" 초기화\n",
    "        \"\"\"\n",
    "        self.loss_fn = loss_fn\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.metric_fn = metric_fn\n",
    "\n",
    "    def train_epoch(self, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 학습 절차\"\"\"\n",
    "        \n",
    "        self.model.train()\n",
    "        train_total_loss = 0\n",
    "        target_lst = []\n",
    "        pred_lst = []\n",
    "        prob_lst = []\n",
    "\n",
    "        for batch_index, (img, label) in enumerate(dataloader):\n",
    "            img = img.to(self.device)\n",
    "            label = label.to(self.device).float()\n",
    "            \n",
    "            pred = self.model(img)\n",
    "            \n",
    "            loss = self.loss_fn(pred[:,1], label)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            \n",
    "            train_total_loss += loss.item()\n",
    "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
    "            target_lst.extend(label.cpu().tolist())\n",
    "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
    "        self.train_mean_loss = train_total_loss / batch_index\n",
    "        self.train_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
    "        msg = f'Epoch {epoch_index}, Train loss: {self.train_mean_loss}, Acc: {self.train_score}, F1-Macro: {f1}'\n",
    "        print(msg)\n",
    "\n",
    "    def validate_epoch(self, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 검증 절차\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        val_total_loss = 0\n",
    "        target_lst = []\n",
    "        pred_lst = []\n",
    "        prob_lst = []\n",
    "\n",
    "        for batch_index, (img, label) in enumerate(dataloader):\n",
    "            img = img.to(self.device)\n",
    "            label = label.to(self.device).float()\n",
    "            pred = self.model(img)\n",
    "            \n",
    "            loss = self.loss_fn(pred[:,1], label)\n",
    "            val_total_loss += loss.item()\n",
    "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
    "            target_lst.extend(label.cpu().tolist())\n",
    "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
    "        self.val_mean_loss = val_total_loss / batch_index\n",
    "        self.validation_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
    "        msg = f'Epoch {epoch_index}, Val loss: {self.val_mean_loss}, Acc: {self.validation_score}, F1-Macro: {f1}'\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aca506-d168-4c9f-8eca-5cdecb122961",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33678d90-a254-48d5-bf09-2a817eeafea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def get_metric_fn(y_pred, y_answer):\n",
    "    \"\"\" 성능을 반환하는 함수\"\"\"\n",
    "    \n",
    "    assert len(y_pred) == len(y_answer), 'The size of prediction and answer are not same.'\n",
    "    accuracy = accuracy_score(y_answer, y_pred)\n",
    "    f1 = f1_score(y_answer, y_pred, average='macro')\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729c079-9d85-49ce-857f-320b0c56a3a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train\n",
    "### 학습을 위한 객체 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19610a4-ad7c-44a0-80cd-9734b5015100",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cea68f0-dfad-47ce-a8ca-00ea01988886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset..\n",
      "Loading val dataset..\n",
      "Train set samples: 581 Val set samples: 65\n"
     ]
    }
   ],
   "source": [
    "# Load dataset & dataloader\n",
    "train_dataset = CustomDataset(data_dir=DATA_DIR, mode='train', input_shape=INPUT_SHAPE)\n",
    "validation_dataset = CustomDataset(data_dir=DATA_DIR, mode='val', input_shape=INPUT_SHAPE)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print('Train set samples:',len(train_dataset),  'Val set samples:', len(validation_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8dae0-8e32-4ac0-a585-858a7095d2a4",
   "metadata": {},
   "source": [
    "#### Load model and other utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb4d52e1-752a-40d5-9b34-c06d3dbdd45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = custom_CNN(NUM_CLS).to(DEVICE)\n",
    "\n",
    "# # Save Initial Model\n",
    "# torch.save(model.state_dict(), 'initial.pt')\n",
    "\n",
    "# Set optimizer, scheduler, loss function, metric function\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler =  optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, max_lr=0.0001, epochs=EPOCHS, steps_per_epoch=len(train_dataloader))\n",
    "loss_fn = nn.BCELoss()\n",
    "metric_fn = get_metric_fn\n",
    "\n",
    "\n",
    "# Set trainer\n",
    "trainer = Trainer(loss_fn, model, DEVICE, metric_fn, optimizer, scheduler)\n",
    "\n",
    "# Set earlystopper\n",
    "early_stopper = LossEarlyStopper(patience=EARLY_STOPPING_PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b881024-3921-4c2c-b9ec-e6b23c4f5ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custom_CNN(\n",
       "  (conv1): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(8, 25, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=21025, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=3, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa8aef-b984-4133-b6b2-e1c85900f724",
   "metadata": {},
   "source": [
    "### epoch 단위 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcc35f70-25fc-48e1-92f8-8633b3b8be80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train loss: 0.764556841717826, Acc: 0.5060240963855421, F1-Macro: 0.3436806678449216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% 1/50 [00:43<35:23, 43.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 1.1947570145130157, Acc: 0.5076923076923077, F1-Macro: 0.336734693877551\n",
      "Epoch 1, Train loss: 0.7169728941387601, Acc: 0.4664371772805508, F1-Macro: 0.31807511737089206\n",
      "Epoch 1, Val loss: 1.000713735818863, Acc: 0.5076923076923077, F1-Macro: 0.336734693877551\n",
      "Validation loss decreased 1.1947570145130157 -> 1.000713735818863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4% 2/50 [01:26<34:38, 43.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.6843900812996758, Acc: 0.504302925989673, F1-Macro: 0.40734444066643993\n",
      "Epoch 2, Val loss: 1.0047152638435364, Acc: 0.5692307692307692, F1-Macro: 0.5190274841437632\n",
      "Early stopping counter 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6% 3/50 [02:09<33:50, 43.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.6564783288372887, Acc: 0.6316695352839932, F1-Macro: 0.6161014227843098\n",
      "Epoch 3, Val loss: 0.7358929961919785, Acc: 0.6153846153846154, F1-Macro: 0.554672513017265\n",
      "Validation loss decreased 1.000713735818863 -> 0.7358929961919785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8% 4/50 [02:52<33:00, 43.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train loss: 0.5926444315248065, Acc: 0.6953528399311532, F1-Macro: 0.6924960753532182\n",
      "Epoch 4, Val loss: 0.6825853288173676, Acc: 0.676923076923077, F1-Macro: 0.6351242983159584\n",
      "Validation loss decreased 0.7358929961919785 -> 0.6825853288173676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 5/50 [03:36<32:28, 43.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train loss: 0.5512094017532136, Acc: 0.7108433734939759, F1-Macro: 0.7062053023188615\n",
      "Epoch 5, Val loss: 1.0974988639354706, Acc: 0.6153846153846154, F1-Macro: 0.5656241646618552\n",
      "Early stopping counter 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12% 6/50 [04:18<31:35, 43.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train loss: 0.48244575162728626, Acc: 0.7555938037865749, F1-Macro: 0.7553843781873385\n",
      "Epoch 6, Val loss: 0.4659470170736313, Acc: 0.8769230769230769, F1-Macro: 0.8761904761904762\n",
      "Validation loss decreased 0.6825853288173676 -> 0.4659470170736313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14% 7/50 [05:01<30:53, 43.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train loss: 0.4233052283525467, Acc: 0.810671256454389, F1-Macro: 0.8106572335987865\n",
      "Epoch 7, Val loss: 0.493279829621315, Acc: 0.7846153846153846, F1-Macro: 0.7804054054054055\n",
      "Early stopping counter 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16% 8/50 [05:45<30:15, 43.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train loss: 0.3987894919183519, Acc: 0.7934595524956971, F1-Macro: 0.7934589406327764\n",
      "Epoch 8, Val loss: 0.4904090166091919, Acc: 0.8307692307692308, F1-Macro: 0.8281663061764\n",
      "Early stopping counter 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18% 9/50 [06:29<29:42, 43.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train loss: 0.3555283380879296, Acc: 0.8433734939759037, F1-Macro: 0.5626827409408993\n",
      "Epoch 9, Val loss: 0.7752856016159058, Acc: 0.8307692307692308, F1-Macro: 0.8293148722845547\n",
      "Early stopping counter 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 10/50 [07:12<28:58, 43.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train loss: 0.3194955007897483, Acc: 0.8795180722891566, F1-Macro: 0.8792573152194566\n",
      "Epoch 10, Val loss: 0.5446661487221718, Acc: 0.8, F1-Macro: 0.7929429061504534\n",
      "Early stopping counter 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22% 11/50 [07:56<28:17, 43.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train loss: 0.26288362261321807, Acc: 0.8984509466437177, F1-Macro: 0.5993691727281198\n",
      "Epoch 11, Val loss: 0.46485792845487595, Acc: 0.8307692307692308, F1-Macro: 0.8266666666666667\n",
      "Validation loss decreased 0.4659470170736313 -> 0.46485792845487595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24% 12/50 [08:39<27:30, 43.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train loss: 0.2575937095615599, Acc: 0.8898450946643718, F1-Macro: 0.889750705661899\n",
      "Epoch 12, Val loss: 0.440654993057251, Acc: 0.7384615384615385, F1-Macro: 0.7384615384615384\n",
      "Validation loss decreased 0.46485792845487595 -> 0.440654993057251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26% 13/50 [09:23<26:48, 43.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train loss: 0.21862823474738333, Acc: 0.927710843373494, F1-Macro: 0.9274164762992576\n",
      "Epoch 13, Val loss: 0.570954717695713, Acc: 0.7692307692307693, F1-Macro: 0.7636363636363637\n",
      "Early stopping counter 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28% 14/50 [10:06<26:06, 43.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train loss: 0.1700389716360304, Acc: 0.9483648881239243, F1-Macro: 0.9481546259280411\n",
      "Epoch 14, Val loss: 0.4497650238336064, Acc: 0.7692307692307693, F1-Macro: 0.7683535281539557\n",
      "Early stopping counter 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 15/50 [10:49<25:17, 43.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Train loss: 0.14232690880695978, Acc: 0.9483648881239243, F1-Macro: 0.9482174688057041\n",
      "Epoch 15, Val loss: 1.2209692597389221, Acc: 0.8, F1-Macro: 0.7998104714522627\n",
      "Early stopping counter 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32% 16/50 [11:33<24:38, 43.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train loss: 0.11204545427527693, Acc: 0.9776247848537005, F1-Macro: 0.9775385484662393\n",
      "Epoch 16, Val loss: 0.4790608361363411, Acc: 0.7692307692307693, F1-Macro: 0.7690120824449184\n",
      "Early stopping counter 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34% 17/50 [12:17<23:57, 43.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train loss: 0.09748435620632437, Acc: 0.9724612736660929, F1-Macro: 0.97232344885078\n",
      "Epoch 17, Val loss: 0.47392392964684404, Acc: 0.8, F1-Macro: 0.799239724400095\n",
      "Early stopping counter 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36% 18/50 [13:01<23:16, 43.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Train loss: 0.07856279756459925, Acc: 0.9896729776247849, F1-Macro: 0.9896212933190425\n",
      "Epoch 18, Val loss: 0.5260882608708926, Acc: 0.7692307692307693, F1-Macro: 0.7656813266041816\n",
      "Early stopping counter 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38% 19/50 [13:45<22:37, 43.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Train loss: 0.0715867065721088, Acc: 0.9845094664371773, F1-Macro: 0.9844356934287015\n",
      "Epoch 19, Val loss: 0.48499242169054924, Acc: 0.7692307692307693, F1-Macro: 0.7690120824449183\n",
      "Early stopping counter 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 20/50 [14:28<21:49, 43.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train loss: 0.04930533722249998, Acc: 0.9982788296041308, F1-Macro: 0.9982714352442751\n",
      "Epoch 20, Val loss: 0.5193452819439699, Acc: 0.7692307692307693, F1-Macro: 0.7690120824449183\n",
      "Early stopping counter 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42% 21/50 [15:12<21:02, 43.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Train loss: 0.04547811651395427, Acc: 1.0, F1-Macro: 1.0\n",
      "Epoch 21, Val loss: 0.5671897018328309, Acc: 0.7692307692307693, F1-Macro: 0.7692307692307692\n",
      "Early stopping counter 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44% 22/50 [15:55<20:17, 43.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Train loss: 0.0387476057642036, Acc: 1.0, F1-Macro: 1.0\n",
      "Epoch 22, Val loss: 0.5514565294142812, Acc: 0.7846153846153846, F1-Macro: 0.7845643939393939\n",
      "Early stopping counter 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46% 23/50 [16:38<19:34, 43.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Train loss: 0.03563912378417121, Acc: 0.9982788296041308, F1-Macro: 0.998270632603189\n",
      "Epoch 23, Val loss: 0.7840234413743019, Acc: 0.7692307692307693, F1-Macro: 0.7656813266041816\n",
      "Early stopping counter 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48% 24/50 [17:22<18:54, 43.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Train loss: 0.027618575427267287, Acc: 1.0, F1-Macro: 1.0\n",
      "Epoch 24, Val loss: 0.5746201686561108, Acc: 0.7538461538461538, F1-Macro: 0.7537878787878789\n",
      "Early stopping counter 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 25/50 [18:07<18:14, 43.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Train loss: 0.01975189955232458, Acc: 1.0, F1-Macro: 1.0\n",
      "Epoch 25, Val loss: 0.5765942633279337, Acc: 0.7692307692307693, F1-Macro: 0.7692307692307692\n",
      "Early stopping counter 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52% 26/50 [18:50<17:29, 43.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Train loss: 0.024368970706644986, Acc: 1.0, F1-Macro: 1.0\n",
      "Epoch 26, Val loss: 0.9213598072528839, Acc: 0.7692307692307693, F1-Macro: 0.7690120824449184\n",
      "Early stopping counter 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54% 27/50 [19:34<16:46, 43.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Train loss: 0.021975598304480728, Acc: 0.9982788296041308, F1-Macro: 0.9982714352442751\n",
      "Epoch 27, Val loss: 1.920305758714676, Acc: 0.7692307692307693, F1-Macro: 0.7690120824449184\n",
      "Early stopping counter 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56% 28/50 [20:18<16:07, 43.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Train loss: 0.016027137223217223, Acc: 1.0, F1-Macro: 1.0\n",
      "Epoch 28, Val loss: 0.7723749876022339, Acc: 0.8, F1-Macro: 0.799239724400095\n",
      "Early stopping counter 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58% 29/50 [21:03<15:26, 44.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Train loss: 0.015790124889463186, Acc: 1.0, F1-Macro: 1.0\n",
      "Epoch 29, Val loss: 0.6304820190816827, Acc: 0.8, F1-Macro: 0.799239724400095\n",
      "Early stopping counter 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 30/50 [21:47<14:43, 44.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Train loss: 0.012013095198199153, Acc: 1.0, F1-Macro: 1.0\n",
      "Epoch 30, Val loss: 0.6167648331029341, Acc: 0.7692307692307693, F1-Macro: 0.7690120824449184\n",
      "Early stopping counter 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62% 31/50 [22:31<13:54, 43.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Train loss: 0.01111464907363471, Acc: 1.0, F1-Macro: 1.0\n",
      "Epoch 31, Val loss: 1.4175937473773956, Acc: 0.7846153846153846, F1-Macro: 0.7841555977229602\n",
      "Early stopping counter 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64% 32/50 [23:14<13:10, 43.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Train loss: 0.010770689126931958, Acc: 1.0, F1-Macro: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64% 32/50 [23:57<13:28, 44.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Val loss: 0.645515990909189, Acc: 0.7846153846153846, F1-Macro: 0.7841555977229602\n",
      "Early stopping counter 20/20\n",
      "Early stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch_index in tqdm(range(EPOCHS)):\n",
    "\n",
    "    trainer.train_epoch(train_dataloader, epoch_index)\n",
    "    trainer.validate_epoch(validation_dataloader, epoch_index)\n",
    "\n",
    "    # early_stopping check\n",
    "    early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
    "\n",
    "    if early_stopper.stop:\n",
    "        print('Early stopped')\n",
    "        break\n",
    "\n",
    "    if early_stopper.save_model:\n",
    "        check_point = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict()\n",
    "        }\n",
    "        torch.save(check_point, 'best.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53514a-e83f-4795-9589-640f26cc2993",
   "metadata": {},
   "source": [
    "## Inference\n",
    "### 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6729cfde-c4b3-4d36-938e-f8bb8d8afef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_MODEL_PATH = 'best.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bbba92-b53c-499f-b5f9-b6ac3edde331",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ced90de9-50ec-4e18-9f42-5a1b493941a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_dir, input_shape):\n",
    "        self.data_dir = data_dir\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # Loading dataset\n",
    "        self.db = self.data_loader()\n",
    "        \n",
    "        # Transform function\n",
    "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading test dataset..')\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
    "            sys.exit()\n",
    "        \n",
    "        db = pd.read_csv(os.path.join(self.data_dir, 'sample_submission.csv'))\n",
    "        return db\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = copy.deepcopy(self.db.loc[index])\n",
    "        \n",
    "        # Loading image\n",
    "        cvimg = cv2.imread(os.path.join(self.data_dir,'test',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
    "        if not isinstance(cvimg, np.ndarray):\n",
    "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
    "\n",
    "        # Preprocessing images\n",
    "        trans_image = self.transform(Image.fromarray(cvimg))\n",
    "\n",
    "        return trans_image, data['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdd31a3d-08cd-48fc-87b0-137976d4d4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset..\n"
     ]
    }
   ],
   "source": [
    "# Load dataset & dataloader\n",
    "test_dataset = TestDataset(data_dir=DATA_DIR, input_shape=INPUT_SHAPE)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53efd72b-172d-4e34-a1dd-65ed8c745b58",
   "metadata": {},
   "source": [
    "### 추론 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16a090ea-bb34-4d3d-a127-b1190e8c416c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3801e-01, 8.5759e-01, 4.3982e-03],\n",
      "        [9.9975e-01, 2.2514e-04, 2.2397e-05],\n",
      "        [9.9552e-01, 3.8589e-03, 6.2211e-04],\n",
      "        [2.4024e-03, 9.9732e-01, 2.7396e-04],\n",
      "        [9.9582e-01, 3.8751e-03, 3.0537e-04],\n",
      "        [3.4187e-03, 9.9551e-01, 1.0666e-03],\n",
      "        [9.0431e-01, 9.2363e-02, 3.3232e-03],\n",
      "        [3.9819e-03, 9.9514e-01, 8.7793e-04],\n",
      "        [9.9998e-01, 1.3759e-05, 5.6169e-06],\n",
      "        [4.7707e-07, 1.0000e+00, 4.7707e-07],\n",
      "        [7.9055e-01, 1.9400e-01, 1.5453e-02],\n",
      "        [2.3019e-01, 7.6789e-01, 1.9185e-03],\n",
      "        [7.4556e-01, 2.4664e-01, 7.7981e-03],\n",
      "        [9.9996e-01, 2.9626e-05, 9.3462e-06],\n",
      "        [9.7935e-01, 2.0368e-02, 2.8672e-04],\n",
      "        [9.9328e-01, 4.3821e-03, 2.3335e-03],\n",
      "        [8.7028e-02, 9.1082e-01, 2.1515e-03],\n",
      "        [9.9993e-01, 5.4847e-05, 1.5152e-05],\n",
      "        [9.4341e-01, 5.6202e-02, 3.8879e-04],\n",
      "        [9.9657e-01, 2.1727e-03, 1.2566e-03],\n",
      "        [9.9985e-01, 1.3203e-04, 1.7241e-05],\n",
      "        [9.9486e-01, 1.9866e-03, 3.1581e-03],\n",
      "        [9.1460e-01, 8.4146e-02, 1.2527e-03],\n",
      "        [3.7278e-03, 9.9489e-01, 1.3805e-03],\n",
      "        [9.9999e-01, 4.8854e-06, 1.4771e-06],\n",
      "        [9.9915e-01, 7.1448e-04, 1.3560e-04],\n",
      "        [9.9993e-01, 4.8535e-05, 1.9800e-05],\n",
      "        [9.4793e-01, 5.1723e-02, 3.4800e-04],\n",
      "        [6.3234e-04, 9.9936e-01, 1.2621e-05],\n",
      "        [1.3535e-01, 8.6307e-01, 1.5859e-03],\n",
      "        [9.3483e-01, 6.4960e-02, 2.0852e-04],\n",
      "        [4.5436e-02, 9.5394e-01, 6.2812e-04]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:04,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.1338e-01, 8.6042e-02, 5.7739e-04],\n",
      "        [4.8740e-01, 5.1118e-01, 1.4212e-03],\n",
      "        [9.9926e-01, 5.4831e-04, 1.9108e-04],\n",
      "        [6.2832e-01, 3.6371e-01, 7.9713e-03],\n",
      "        [9.9986e-01, 1.3426e-04, 1.5110e-06],\n",
      "        [2.2354e-04, 9.9964e-01, 1.3458e-04],\n",
      "        [8.1557e-01, 1.8050e-01, 3.9229e-03],\n",
      "        [3.4005e-02, 9.6463e-01, 1.3607e-03],\n",
      "        [5.1831e-04, 9.9928e-01, 1.9746e-04],\n",
      "        [1.1261e-01, 8.8409e-01, 3.3070e-03],\n",
      "        [9.8835e-01, 8.8927e-03, 2.7617e-03],\n",
      "        [8.8881e-02, 9.1027e-01, 8.5066e-04],\n",
      "        [4.0766e-01, 5.9106e-01, 1.2794e-03],\n",
      "        [4.7891e-04, 9.9929e-01, 2.3139e-04],\n",
      "        [2.6033e-02, 9.7274e-01, 1.2247e-03],\n",
      "        [1.0000e+00, 1.2000e-06, 1.2000e-06],\n",
      "        [9.9030e-01, 9.6025e-03, 9.9422e-05],\n",
      "        [9.7843e-01, 2.0672e-02, 8.9695e-04],\n",
      "        [9.5035e-02, 9.0239e-01, 2.5742e-03],\n",
      "        [1.4614e-04, 9.9981e-01, 3.8972e-05],\n",
      "        [7.3700e-01, 2.5326e-01, 9.7383e-03],\n",
      "        [9.0691e-01, 8.8441e-02, 4.6490e-03],\n",
      "        [2.4823e-03, 9.9730e-01, 2.1326e-04],\n",
      "        [7.9192e-01, 2.0692e-01, 1.1678e-03],\n",
      "        [4.1654e-02, 9.5676e-01, 1.5908e-03],\n",
      "        [2.9857e-03, 9.9681e-01, 2.0786e-04],\n",
      "        [9.9984e-01, 1.4183e-04, 1.6319e-05],\n",
      "        [2.5436e-02, 9.7258e-01, 1.9810e-03],\n",
      "        [1.5511e-01, 8.4428e-01, 6.0630e-04],\n",
      "        [9.9961e-01, 3.6673e-04, 2.5161e-05],\n",
      "        [9.9997e-01, 1.8820e-05, 7.0453e-06],\n",
      "        [9.9709e-01, 1.1365e-03, 1.7744e-03]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:06,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.0425e-04, 9.9941e-01, 8.7187e-05],\n",
      "        [1.5135e-05, 9.9998e-01, 4.7989e-06],\n",
      "        [2.7440e-01, 7.2495e-01, 6.4874e-04],\n",
      "        [9.1990e-01, 7.9553e-02, 5.4568e-04],\n",
      "        [7.2264e-04, 9.9901e-01, 2.7032e-04],\n",
      "        [9.8680e-01, 1.2784e-02, 4.1208e-04],\n",
      "        [9.8019e-01, 1.5271e-02, 4.5382e-03],\n",
      "        [9.9800e-01, 1.7619e-03, 2.4023e-04],\n",
      "        [9.9995e-01, 1.0613e-05, 3.7890e-05],\n",
      "        [9.9975e-01, 2.4134e-04, 1.0664e-05],\n",
      "        [5.6133e-06, 9.9999e-01, 3.7368e-06],\n",
      "        [9.9999e-01, 7.6593e-06, 3.4212e-06],\n",
      "        [9.9981e-01, 7.5773e-05, 1.1499e-04],\n",
      "        [9.5777e-01, 4.2225e-02, 7.5419e-06],\n",
      "        [2.4648e-02, 9.7514e-01, 2.1342e-04],\n",
      "        [2.0938e-01, 7.8865e-01, 1.9693e-03],\n",
      "        [5.2303e-04, 9.9946e-01, 1.3764e-05],\n",
      "        [9.9244e-01, 6.5077e-03, 1.0513e-03],\n",
      "        [9.8780e-01, 1.1437e-02, 7.5943e-04],\n",
      "        [2.1036e-02, 9.7822e-01, 7.4201e-04],\n",
      "        [1.0619e-01, 8.9042e-01, 3.3894e-03],\n",
      "        [8.3669e-01, 1.6222e-01, 1.0845e-03],\n",
      "        [5.3748e-01, 4.5884e-01, 3.6869e-03],\n",
      "        [9.8724e-01, 1.1067e-02, 1.6908e-03],\n",
      "        [9.3795e-01, 5.8617e-02, 3.4329e-03],\n",
      "        [4.9508e-01, 5.0051e-01, 4.4014e-03],\n",
      "        [9.4346e-01, 5.6482e-02, 5.6654e-05],\n",
      "        [9.9174e-01, 5.2724e-03, 2.9898e-03],\n",
      "        [8.9293e-01, 1.0655e-01, 5.1326e-04],\n",
      "        [3.8374e-05, 9.9993e-01, 3.3875e-05],\n",
      "        [9.9956e-01, 4.1197e-04, 3.1233e-05],\n",
      "        [2.7507e-01, 7.1865e-01, 6.2801e-03]], device='cuda:0')\n",
      "tensor([[8.0683e-02, 9.1869e-01, 6.2751e-04],\n",
      "        [2.4584e-01, 7.5372e-01, 4.4084e-04],\n",
      "        [4.1759e-01, 5.8203e-01, 3.8834e-04],\n",
      "        [3.2022e-01, 6.7755e-01, 2.2292e-03]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:06,  1.62s/it]\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(TRAINED_MODEL_PATH)['model'])\n",
    "\n",
    "# Prediction\n",
    "file_lst = []\n",
    "pred_lst = []\n",
    "prob_lst = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_index, (img, file_num) in tqdm(enumerate(test_dataloader)):\n",
    "        img = img.to(DEVICE)\n",
    "        pred = model(img)\n",
    "        print(pred)\n",
    "        file_lst.extend(list(file_num))\n",
    "        pred_lst.extend(pred.argmax(dim=1).tolist())\n",
    "        prob_lst.extend(pred[:, 1].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056169d1-64a8-4b81-8daf-722b029cf2b9",
   "metadata": {},
   "source": [
    "### 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f133cd86-b87b-4f8b-ae0e-c240655ae9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'file_name':file_lst, 'COVID':pred_lst})\n",
    "# df.sort_values(by=['file_name'], inplace=True)\n",
    "df.to_csv('prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
