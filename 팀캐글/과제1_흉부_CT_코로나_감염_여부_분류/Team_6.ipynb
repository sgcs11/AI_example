{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "iliJuq6afHjz",
      "metadata": {
        "id": "iliJuq6afHjz"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f51ba7c1-0393-47ec-89d9-f6f97072773b",
      "metadata": {
        "id": "f51ba7c1-0393-47ec-89d9-f6f97072773b"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update && apt-get install -y python3-opencv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cmoKWjyNjTq",
        "outputId": "443dc696-dd07-4f39-ceb1-98ac00723677"
      },
      "id": "5cmoKWjyNjTq",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [917 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [21.1 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.0 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [783 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [816 kB]\n",
            "Get:19 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,470 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,004 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,565 kB]\n",
            "Get:23 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,248 kB]\n",
            "Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,826 kB]\n",
            "Get:26 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [936 kB]\n",
            "Get:27 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:28 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [42.8 kB]\n",
            "Fetched 15.0 MB in 9s (1,631 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following additional packages will be installed:\n",
            "  python3-numpy\n",
            "Suggested packages:\n",
            "  python-numpy-doc python3-nose python3-numpy-dbg\n",
            "The following NEW packages will be installed:\n",
            "  python3-numpy python3-opencv\n",
            "0 upgraded, 2 newly installed, 0 to remove and 65 not upgraded.\n",
            "Need to get 2,477 kB of archives.\n",
            "After this operation, 13.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-numpy amd64 1:1.13.3-2ubuntu1 [1,943 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-opencv amd64 3.2.0+dfsg-4ubuntu0.1 [534 kB]\n",
            "Fetched 2,477 kB in 2s (1,149 kB/s)\n",
            "Selecting previously unselected package python3-numpy.\n",
            "(Reading database ... 155113 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-numpy_1%3a1.13.3-2ubuntu1_amd64.deb ...\n",
            "Unpacking python3-numpy (1:1.13.3-2ubuntu1) ...\n",
            "Selecting previously unselected package python3-opencv.\n",
            "Preparing to unpack .../python3-opencv_3.2.0+dfsg-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking python3-opencv (3.2.0+dfsg-4ubuntu0.1) ...\n",
            "Setting up python3-numpy (1:1.13.3-2ubuntu1) ...\n",
            "Setting up python3-opencv (3.2.0+dfsg-4ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "98a45c7e-10ca-4fd1-9fd4-6326313a631a",
      "metadata": {
        "id": "98a45c7e-10ca-4fd1-9fd4-6326313a631a"
      },
      "outputs": [],
      "source": [
        "import os, torch, copy, cv2, sys, random\n",
        "# from datetime import datetime, timezone, timedelta\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc, confusion_matrix, average_precision_score\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect google drive & Change directory"
      ],
      "metadata": {
        "id": "_h67WQqUN4Sn"
      },
      "id": "_h67WQqUN4Sn"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/팀 프로젝트/COVID-19_detection_with_CT/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNSlhSFsNyV6",
        "outputId": "976eeb6a-1c14-49de-aa5e-531c91d1237f"
      },
      "id": "mNSlhSFsNyV6",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a6c255b-b30d-4ffd-a663-bc01a2c37954",
      "metadata": {
        "id": "3a6c255b-b30d-4ffd-a663-bc01a2c37954"
      },
      "source": [
        "## Set Arguments & hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8f9c4250-2257-404f-941d-58eff1e9eb38",
      "metadata": {
        "id": "8f9c4250-2257-404f-941d-58eff1e9eb38"
      },
      "outputs": [],
      "source": [
        "# 시드(seed) 설정\n",
        "\n",
        "RANDOM_SEED = 2022\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9d69a8bc-2e64-4de6-928f-4e16957f6af9",
      "metadata": {
        "id": "9d69a8bc-2e64-4de6-928f-4e16957f6af9"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "\n",
        "### 데이터 디렉토리 설정 ###\n",
        "DATA_DIR= 'data'\n",
        "NUM_CLS = 2\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 17\n",
        "LEARNING_RATE = 0.0005\n",
        "EARLY_STOPPING_PATIENCE = 3\n",
        "INPUT_SHAPE = 384\n",
        "K_FOLDS = 5\n",
        "origin_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
        "NUM_ORIGIN_DATA = len(origin_df)\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7db9154a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7db9154a",
        "outputId": "fb45c9d2-27e3-45b7-80d0-b3e1fcc6e936"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# check device\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Augmentation variable\n",
        "VFLIP = True\n",
        "HFLIP = True\n",
        "ROTATE = True\n",
        "FLIP_ROTATE = True\n",
        "ANGLE = None"
      ],
      "metadata": {
        "id": "1G4hgYHqEm-6"
      },
      "id": "1G4hgYHqEm-6",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmetation"
      ],
      "metadata": {
        "id": "SYgCJel2Ehph"
      },
      "id": "SYgCJel2Ehph"
    },
    {
      "cell_type": "code",
      "source": [
        "# ./data/augmentation 위치에 이미지를 생성하도록 만듦\n",
        "# vflip : 상하로 뒤집을건지, hflip : 좌우로 뒤집을건지, rotate : 회전을 할건지 (한다면) angle : 지정한값으로 할건지(비우면 random)\n",
        "def createimage(vflip=True, hflip=True, rotate=True, flip_rotate=True, angle=None):\n",
        "    # 난수 일관성을 위한 시드 초기화\n",
        "    np.random.seed(RANDOM_SEED)\n",
        "    origin_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
        "    \n",
        "    if not os.path.isdir(os.path.join(DATA_DIR, 'augmentation2')):\n",
        "        os.makedirs(os.path.join(DATA_DIR, 'augmentation2'))\n",
        "\n",
        "    # save original image\n",
        "    for i in tqdm(range(NUM_ORIGIN_DATA)):\n",
        "        img = cv2.imread(f'./{DATA_DIR}/train/{i}.png')\n",
        "        cv2.imwrite(f'./{DATA_DIR}/augmentation2/{i}.png', img)\n",
        "        \n",
        "\n",
        "    # vertical flip\n",
        "    if vflip:\n",
        "        for i in tqdm(range(NUM_ORIGIN_DATA)):\n",
        "            img = cv2.imread(f'./{DATA_DIR}/train/{i}.png')\n",
        "            vflip_img = cv2.flip(img, 0)\n",
        "            cv2.imwrite(f'./{DATA_DIR}/augmentation2/{i}_vflip.png', vflip_img)\n",
        "            origin_df.loc[len(origin_df)] = [f'{i}_vflip.png', origin_df.iloc[i]['COVID']]\n",
        "\n",
        "        \n",
        "    # horizontal filp\n",
        "    if hflip:\n",
        "        for i in tqdm(range(NUM_ORIGIN_DATA)):\n",
        "            img = cv2.imread(f'./{DATA_DIR}/train/{i}.png')\n",
        "            hflip_img = cv2.flip(img, 1)\n",
        "            cv2.imwrite(f'./{DATA_DIR}/augmentation2/{i}_hflip.png', hflip_img)\n",
        "            origin_df.loc[len(origin_df)] = [f'{i}_hflip.png', origin_df.iloc[i]['COVID']]\n",
        "\n",
        "    # rotate\n",
        "    if rotate:\n",
        "        for i in tqdm(range(NUM_ORIGIN_DATA)):\n",
        "            img = cv2.imread(f'./{DATA_DIR}/train/{i}.png')\n",
        "            h, w = img.shape[:2]\n",
        "            # rotate by Specific value\n",
        "            if angle:\n",
        "                rotation = cv2.getRotationMatrix2D((h/2, w/2), angle, 1)\n",
        "                rotate_img = cv2.warpAffine(img, rotation, (h, w))\n",
        "            # rotate by random value(5 ~ 35)\n",
        "            else:\n",
        "                rand_angle = np.random.randint(30)\n",
        "                rotation = cv2.getRotationMatrix2D((h/2, w/2), rand_angle, 1)\n",
        "                rotate_img = cv2.warpAffine(img, rotation, (h, w))\n",
        "            cv2.imwrite(f'./{DATA_DIR}/augmentation2/{i}_rotate.png', rotate_img)\n",
        "            origin_df.loc[len(origin_df)] = [f'{i}_rotate.png', origin_df.iloc[i]['COVID']]\n",
        "\n",
        "    # flip-rotate\n",
        "    if flip_rotate:\n",
        "        for i in tqdm(range(NUM_ORIGIN_DATA)):\n",
        "            img = cv2.imread(f'./{DATA_DIR}/train/{i}.png')\n",
        "            hflip_img = cv2.flip(img, 1)\n",
        "            h, w = hflip_img.shape[:2]\n",
        "            # rotate by Specific value\n",
        "            if angle:\n",
        "                rotation = cv2.getRotationMatrix2D((h/2, w/2), angle, 1)\n",
        "                rotate_img = cv2.warpAffine(hflip_img, rotation, (h, w))\n",
        "            # rotate by random value\n",
        "            else:\n",
        "                rand_angle = np.random.randint(30)\n",
        "                rotation = cv2.getRotationMatrix2D((h/2, w/2), 5+rand_angle, 1)\n",
        "                rotate_img = cv2.warpAffine(hflip_img, rotation, (h, w))\n",
        "            cv2.imwrite(f'./{DATA_DIR}/augmentation2/{i}_flip_rotate.png', rotate_img)\n",
        "            origin_df.loc[len(origin_df)] = [f'{i}_flip_rotate.png', origin_df.iloc[i]['COVID']]\n",
        "\n",
        "    print('\\nsave csv file...')\n",
        "    origin_df.to_csv(os.path.join(DATA_DIR, 'augmentation2.csv'))\n",
        "    print(\"ALL JOBS FINISHED\")\n",
        "\n",
        "    return origin_df"
      ],
      "metadata": {
        "id": "IddO3F57Eg41"
      },
      "id": "IddO3F57Eg41",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "코랩이라 그런진 몰라도 기존에 이미 변환시킨 파일이 있는 상태에서 createimage를 실행시키면 시간이 너무 오래걸림.<br>\n",
        "어차피 이전에 이미 이미지를 생성했다면 필요한 파일은 다 있으므로 생략해도 됨"
      ],
      "metadata": {
        "id": "IMDVl240cdTA"
      },
      "id": "IMDVl240cdTA"
    },
    {
      "cell_type": "code",
      "source": [
        "# new_df = createimage(VFLIP, HFLIP, ROTATE, FLIP_ROTATE, ANGLE)"
      ],
      "metadata": {
        "id": "93BfHOuRFdRE"
      },
      "id": "93BfHOuRFdRE",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d44807b0-7788-49ec-aff2-c756e4513c5e",
      "metadata": {
        "id": "d44807b0-7788-49ec-aff2-c756e4513c5e"
      },
      "source": [
        "# Define Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5b81fa5-3756-46aa-b3cb-6f19879aba05",
      "metadata": {
        "id": "a5b81fa5-3756-46aa-b3cb-6f19879aba05"
      },
      "source": [
        "## Train & Validation Set loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "04642777-c2e0-439b-9692-f6c571a86521",
      "metadata": {
        "id": "04642777-c2e0-439b-9692-f6c571a86521"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    ####################################################################\n",
        "    ####          인자값에 mode 삭제 후 idx를 추가해줘야함          ####\n",
        "    ####################################################################\n",
        "    def __init__(self, data_dir, idx, input_shape):\n",
        "        self.data_dir = data_dir\n",
        "        ####################################################################\n",
        "        ####          mode를 삭제했기 때문에 이부분도 수정해줌          ####\n",
        "        ####################################################################\n",
        "        self.idx = idx\n",
        "        self.input_shape = input_shape\n",
        "        \n",
        "        # Loading dataset\n",
        "        self.db = self.data_loader()\n",
        "        \n",
        "        # Dataset split\n",
        "        ####################################################################\n",
        "        ####          mode를 삭제했기 때문에 이부분도 수정해줌          ####\n",
        "        ####################################################################\n",
        "        self.db = self.db.iloc[self.idx]\n",
        "        self.db.reset_index(inplace=True)\n",
        "            \n",
        "        # Transform function\n",
        "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    def data_loader(self):\n",
        "        ####################################################################\n",
        "        ####          mode를 삭제했기 때문에 이부분도 수정해줌          ####\n",
        "        ####################################################################        \n",
        "        print('Loading dataset..')\n",
        "        if not os.path.isdir(self.data_dir):\n",
        "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
        "            sys.exit()\n",
        "        \n",
        "        # (COVID : 1, No : 0)\n",
        "        ####################################################################\n",
        "        ####          읽어올 label 정보 csv를 train에서 바꿔줌          ####\n",
        "        ####################################################################\n",
        "        db = pd.read_csv(os.path.join(self.data_dir, 'augmentation2.csv'))\n",
        "        \n",
        "        return db\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.db)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data = copy.deepcopy(self.db.loc[index])\n",
        "\n",
        "        # Loading image\n",
        "        ####################################################################\n",
        "        ####           이미지를 읽어올 경로를 train에서 바꿔줌          ####\n",
        "        ####################################################################\n",
        "        cvimg = cv2.imread(os.path.join(self.data_dir,'augmentation2',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
        "        if not isinstance(cvimg, np.ndarray):\n",
        "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
        "\n",
        "        # Preprocessing images\n",
        "        trans_image = self.transform(Image.fromarray(cvimg))\n",
        "\n",
        "        ####################################################################\n",
        "        ####           리턴값에 data['file_name'] 추가해줘야함          ####\n",
        "        ####################################################################\n",
        "        return trans_image, data['COVID'], data['file_name']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61b27520-c82c-4ec8-ae0b-119a79167f09",
      "metadata": {
        "id": "61b27520-c82c-4ec8-ae0b-119a79167f09"
      },
      "source": [
        "# Define Model(VGG-16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bcea77c5",
      "metadata": {
        "id": "bcea77c5"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import vgg16\n",
        "\n",
        "\n",
        "class VGG16(nn.Module):\n",
        "    def __init__(self, NUM_CLS):\n",
        "        super(VGG16, self).__init__()\n",
        "        self.vgg = vgg16(pretrained=False)\n",
        "        self.features_conv = self.vgg.features\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(73728, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, NUM_CLS),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features_conv(x)\n",
        "        x = torch.flatten(x,1)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d056905-1f77-4579-a260-07bb1056f6db",
      "metadata": {
        "id": "1d056905-1f77-4579-a260-07bb1056f6db"
      },
      "source": [
        "# Define Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EarlyStopper"
      ],
      "metadata": {
        "id": "ID9oc2YwwrNC"
      },
      "id": "ID9oc2YwwrNC"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1b4c3315-ebca-4e6b-a8f2-1281ccd0bb87",
      "metadata": {
        "id": "1b4c3315-ebca-4e6b-a8f2-1281ccd0bb87"
      },
      "outputs": [],
      "source": [
        "class LossEarlyStopper():\n",
        "    \"\"\"Early stopper\n",
        "    \n",
        "    Attributes:\n",
        "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
        "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가, 감소 시 0으로 리셋\n",
        "        min_loss (float): 최소 loss\n",
        "        stop (bool): True 일 때 학습 중단\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, patience: int)-> None:\n",
        "        self.patience = patience\n",
        "\n",
        "        self.patience_counter = 0\n",
        "        self.min_loss = np.Inf\n",
        "        self.stop = False\n",
        "        self.save_model = False\n",
        "\n",
        "    def check_early_stopping(self, loss: float)-> None:\n",
        "        \"\"\"Early stopping 여부 판단\"\"\"  \n",
        "\n",
        "        if self.min_loss == np.Inf:\n",
        "            self.min_loss = loss\n",
        "            return None\n",
        "\n",
        "        elif loss > self.min_loss:\n",
        "            self.patience_counter += 1\n",
        "            msg = f\"Early stopping counter {self.patience_counter}/{self.patience}\"\n",
        "\n",
        "            if self.patience_counter == self.patience:\n",
        "                self.stop = True\n",
        "                \n",
        "        elif loss <= self.min_loss:\n",
        "            self.patience_counter = 0\n",
        "            self.save_model = True\n",
        "            msg = f\"Validation loss decreased {self.min_loss} -> {loss}\"\n",
        "            self.min_loss = loss\n",
        "        \n",
        "        print(msg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aaffd8d-b025-42c1-8dd8-69529487389e",
      "metadata": {
        "id": "1aaffd8d-b025-42c1-8dd8-69529487389e"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5faaac1b-64c3-4659-82de-d4309502f29a",
      "metadata": {
        "id": "5faaac1b-64c3-4659-82de-d4309502f29a"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    \"\"\" epoch에 대한 학습 및 검증 절차 정의\"\"\"\n",
        "    \n",
        "    def __init__(self, loss_fn, model, device, metric_fn, optimizer=None, scheduler=None):\n",
        "        \"\"\" 초기화\n",
        "        \"\"\"\n",
        "        self.loss_fn = loss_fn\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.metric_fn = metric_fn\n",
        "\n",
        "    def train_epoch(self, dataloader, epoch_index):\n",
        "        \"\"\" 한 epoch에서 수행되는 학습 절차\"\"\"\n",
        "        \n",
        "        self.model.train()\n",
        "        train_total_loss = 0\n",
        "        target_lst = []\n",
        "        pred_lst = []\n",
        "        prob_lst = []\n",
        "\n",
        "        for batch_index, (img, label, _) in enumerate(dataloader):\n",
        "            img = img.to(self.device)\n",
        "            label = label.to(self.device).float()\n",
        "            \n",
        "            pred = self.model(img)\n",
        "            \n",
        "            loss = self.loss_fn(pred[:,1], label)\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.scheduler.step()\n",
        "            \n",
        "            train_total_loss += loss.item()\n",
        "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
        "            target_lst.extend(label.cpu().tolist())\n",
        "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        self.train_mean_loss = train_total_loss / batch_index\n",
        "        self.train_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
        "        msg = f'\\nEpoch {epoch_index}, Train loss: {self.train_mean_loss}, Acc: {self.train_score}, F1-Macro: {f1}'\n",
        "        print(msg)\n",
        "\n",
        "    def validate_epoch(self, dataloader, epoch_index):\n",
        "        \"\"\" 한 epoch에서 수행되는 검증 절차\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        val_total_loss = 0\n",
        "        target_lst = []\n",
        "        pred_lst = []\n",
        "        prob_lst = []\n",
        "\n",
        "        for batch_index, (img, label, _) in enumerate(dataloader):\n",
        "            img = img.to(self.device)\n",
        "            label = label.to(self.device).float()\n",
        "            pred = self.model(img)\n",
        "            \n",
        "            loss = self.loss_fn(pred[:,1], label)\n",
        "            val_total_loss += loss.item()\n",
        "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
        "            target_lst.extend(label.cpu().tolist())\n",
        "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "        self.val_mean_loss = val_total_loss / batch_index\n",
        "        self.validation_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
        "        msg = f'\\nEpoch {epoch_index}, Val loss: {self.val_mean_loss}, Acc: {self.validation_score}, F1-Macro: {f1}'\n",
        "        print(msg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2aca506-d168-4c9f-8eca-5cdecb122961",
      "metadata": {
        "id": "e2aca506-d168-4c9f-8eca-5cdecb122961"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "33678d90-a254-48d5-bf09-2a817eeafea3",
      "metadata": {
        "id": "33678d90-a254-48d5-bf09-2a817eeafea3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def get_metric_fn(y_pred, y_answer):\n",
        "    \"\"\" 성능을 반환하는 함수\"\"\"\n",
        "    \n",
        "    assert len(y_pred) == len(y_answer), 'The size of prediction and answer are not same.'\n",
        "    accuracy = accuracy_score(y_answer, y_pred)\n",
        "    f1 = f1_score(y_answer, y_pred, average='macro')\n",
        "    return accuracy, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d729c079-9d85-49ce-857f-320b0c56a3a8",
      "metadata": {
        "id": "d729c079-9d85-49ce-857f-320b0c56a3a8",
        "tags": []
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bb8dae0-8e32-4ac0-a585-858a7095d2a4",
      "metadata": {
        "id": "3bb8dae0-8e32-4ac0-a585-858a7095d2a4"
      },
      "source": [
        "## Load utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "cb4d52e1-752a-40d5-9b34-c06d3dbdd45a",
      "metadata": {
        "id": "cb4d52e1-752a-40d5-9b34-c06d3dbdd45a"
      },
      "outputs": [],
      "source": [
        "# Set optimizer, scheduler, loss function, metric function\n",
        "loss_fn = nn.BCELoss()\n",
        "metric_fn = get_metric_fn\n",
        "early_stopper = LossEarlyStopper(patience=EARLY_STOPPING_PATIENCE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5aa8aef-b984-4133-b6b2-e1c85900f724",
      "metadata": {
        "id": "d5aa8aef-b984-4133-b6b2-e1c85900f724"
      },
      "source": [
        "## K-Fold 학습 진행"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=RANDOM_SEED)"
      ],
      "metadata": {
        "id": "xoUF1C-EM3V8"
      },
      "id": "xoUF1C-EM3V8",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "메모리 부족으로(Cuda memory out)로 실행이안됨. 다행히 1fold의 학습은 가능하므로 각 세션마다 하나의 fold조합을 학습시키면서 모델을 저장했음"
      ],
      "metadata": {
        "id": "AzmWjxkEb2YW"
      },
      "id": "AzmWjxkEb2YW"
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list = [[] for _ in range(EPOCHS)]\n",
        "val_loss_list = [[] for _ in range(EPOCHS)]\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(range(646))):\n",
        "    print(f'============================{fold+1}th fold============================')\n",
        "\n",
        "    # cuda memory out 문제 때문에 각 fold 별로 한 번씩 실행해줬음\n",
        "    if fold == 0:\n",
        "        continue\n",
        "    \n",
        "    if fold == 1:\n",
        "        continue\n",
        "\n",
        "    if fold == 2:\n",
        "        continue\n",
        "\n",
        "    if fold == 3:\n",
        "        continue\n",
        "\n",
        "\n",
        "    augmentations = 0\n",
        "    length = len(train_idx)\n",
        "    if VFLIP:\n",
        "        augmentations += 1\n",
        "        vflip_idx = train_idx[:length] + (NUM_ORIGIN_DATA * augmentations)\n",
        "        train_idx = np.concatenate((train_idx, vflip_idx))\n",
        "    if HFLIP:\n",
        "        augmentations += 1\n",
        "        hflip_idx = train_idx[:length] + (NUM_ORIGIN_DATA * augmentations)\n",
        "        train_idx = np.concatenate((train_idx, hflip_idx))\n",
        "    if ROTATE:\n",
        "        augmentations += 1\n",
        "        rotate_idx = train_idx[:length] + (NUM_ORIGIN_DATA * augmentations)\n",
        "        train_idx = np.concatenate((train_idx, rotate_idx))\n",
        "    if FLIP_ROTATE:\n",
        "        augmentations += 1\n",
        "        frotate_idx = train_idx[:length] + (NUM_ORIGIN_DATA * augmentations)\n",
        "        train_idx = np.concatenate((train_idx, frotate_idx))\n",
        "\n",
        "    train_dataset = CustomDataset(data_dir=DATA_DIR, idx=train_idx, input_shape=INPUT_SHAPE)\n",
        "    validation_dataset = CustomDataset(data_dir=DATA_DIR, idx=val_idx, input_shape=INPUT_SHAPE)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    model = VGG16(NUM_CLS).to(DEVICE)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    scheduler =  optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, max_lr=0.0001, epochs=EPOCHS, steps_per_epoch=len(train_dataloader))\n",
        "\n",
        "    # Set trainer\n",
        "    trainer = Trainer(loss_fn, model, DEVICE, metric_fn, optimizer, scheduler)\n",
        "\n",
        "    for epoch_index in tqdm(range(EPOCHS)):\n",
        "        trainer.train_epoch(train_dataloader, epoch_index)\n",
        "        trainer.validate_epoch(validation_dataloader, epoch_index)\n",
        "\n",
        "        train_loss = trainer.train_mean_loss\n",
        "        val_loss = trainer.val_mean_loss\n",
        "        \n",
        "        train_loss_list[epoch_index].append(train_loss)\n",
        "        val_loss_list[epoch_index].append(val_loss)\n",
        "\n",
        "        early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
        "\n",
        "        if early_stopper.stop:\n",
        "            print('Early stopped')\n",
        "            break\n",
        "\n",
        "        if early_stopper.save_model:\n",
        "            torch.save(model.state_dict(), f\"{fold}th_vgg16.pt\")\n",
        "            early_stopper.save_model = False\n",
        "\n",
        "        del train_loss, val_loss\n",
        "        torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGha98tTMuVc",
        "outputId": "df8221fe-a009-4344-826c-803985f0e146"
      },
      "id": "iGha98tTMuVc",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================1th fold============================\n",
            "============================2th fold============================\n",
            "============================3th fold============================\n",
            "============================4th fold============================\n",
            "============================5th fold============================\n",
            "Loading dataset..\n",
            "Loading dataset..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0, Train loss: 0.6936127441494089, Acc: 0.5442940038684719, F1-Macro: 0.5402983389249992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [17:18<2:35:42, 1038.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0, Val loss: 0.7790010145732335, Acc: 0.6666666666666666, F1-Macro: 0.6525524585029753\n",
            "\n",
            "Epoch 1, Train loss: 0.6372991958142895, Acc: 0.6460348162475822, F1-Macro: 0.6460212551120785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [20:14<1:10:48, 531.08s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1, Val loss: 0.9865264509405408, Acc: 0.6666666666666666, F1-Macro: 0.6626938279112192\n",
            "Early stopping counter 1/3\n",
            "\n",
            "Epoch 2, Train loss: 0.557808152939144, Acc: 0.7276595744680852, F1-Macro: 0.7270212702127021\n",
            "\n",
            "Epoch 2, Val loss: 0.6388797632285527, Acc: 0.7364341085271318, F1-Macro: 0.7261488511488512\n",
            "Validation loss decreased 0.7790010145732335 -> 0.6388797632285527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [23:18<43:28, 372.61s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3, Train loss: 0.4663315060499467, Acc: 0.7752417794970986, F1-Macro: 0.7745993992959219\n",
            "\n",
            "Epoch 3, Val loss: 0.5461782940796444, Acc: 0.7751937984496124, F1-Macro: 0.7749774436090224\n",
            "Validation loss decreased 0.6388797632285527 -> 0.5461782940796444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [26:21<29:47, 297.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4, Train loss: 0.39018706320539903, Acc: 0.818568665377176, F1-Macro: 0.8183676315902624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [29:17<21:09, 253.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4, Val loss: 0.6024786744798932, Acc: 0.7984496124031008, F1-Macro: 0.7948874755381605\n",
            "Early stopping counter 1/3\n",
            "\n",
            "Epoch 5, Train loss: 0.30500842723995447, Acc: 0.8646034816247582, F1-Macro: 0.8642758820155004\n",
            "\n",
            "Epoch 5, Val loss: 0.48888204991817474, Acc: 0.7751937984496124, F1-Macro: 0.7743258731978042\n",
            "Validation loss decreased 0.5461782940796444 -> 0.48888204991817474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [32:20<15:18, 229.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6, Train loss: 0.2169843999374854, Acc: 0.9090909090909091, F1-Macro: 0.9087671128776728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [35:16<10:36, 212.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6, Val loss: 0.6240857727825642, Acc: 0.8062015503875969, F1-Macro: 0.8054533389636243\n",
            "Early stopping counter 1/3\n",
            "\n",
            "Epoch 7, Train loss: 0.13387517403737692, Acc: 0.9481624758220503, F1-Macro: 0.9479802415324285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [38:12<06:41, 200.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7, Val loss: 0.6325884993587222, Acc: 0.813953488372093, F1-Macro: 0.8120446818844098\n",
            "Early stopping counter 2/3\n",
            "\n",
            "Epoch 8, Train loss: 0.08482989236884016, Acc: 0.9682785299806577, F1-Macro: 0.9681670134750682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [41:08<10:17, 308.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8, Val loss: 0.7395175695419312, Acc: 0.8062015503875969, F1-Macro: 0.8057813911472447\n",
            "Early stopping counter 3/3\n",
            "Early stopped\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check loss & acc"
      ],
      "metadata": {
        "id": "JNiTt8sOw4zO"
      },
      "id": "JNiTt8sOw4zO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체 FOLD를 순회하지 못했으므로 아래 acc & loss 그래프 셀은 생략함"
      ],
      "metadata": {
        "id": "BalSXBE7cRHa"
      },
      "id": "BalSXBE7cRHa"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "mean_train_loss = [np.mean(train_loss_list[i]) for i in range(EPOCHS)]\n",
        "mean_val_loss = [np.mean(val_loss_list[i]) for i in range(EPOCHS)]\n",
        "\n",
        "loss_ax.plot(mean_train_loss, 'y', label='train loss')\n",
        "loss_ax.plot(mean_val_loss, 'r', label='val loss')\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dcRhC0tqM8Dz"
      },
      "id": "dcRhC0tqM8Dz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmin(mean_val_loss)"
      ],
      "metadata": {
        "id": "AeK0l-fUwKjX"
      },
      "id": "AeK0l-fUwKjX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fe53514a-e83f-4795-9589-640f26cc2993",
      "metadata": {
        "id": "fe53514a-e83f-4795-9589-640f26cc2993"
      },
      "source": [
        "# Inference\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Model"
      ],
      "metadata": {
        "id": "nZBUr6WY9JgC"
      },
      "id": "nZBUr6WY9JgC"
    },
    {
      "cell_type": "code",
      "source": [
        "model1_path = '0th_vgg16.pt'\n",
        "model2_path = '1th_vgg16.pt'\n",
        "model3_path = '2th_vgg16.pt'\n",
        "model4_path = '3th_vgg16.pt'\n",
        "model5_path = '4th_vgg16.pt'"
      ],
      "metadata": {
        "id": "EbYfxsVI_lIX"
      },
      "id": "EbYfxsVI_lIX",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fold1 model\n",
        "model1 = VGG16(NUM_CLS).to(DEVICE)\n",
        "model1.load_state_dict(torch.load(model1_path, map_location='cpu'))\n",
        "\n",
        "# fold2 model\n",
        "model2 = VGG16(NUM_CLS).to(DEVICE)\n",
        "model2.load_state_dict(torch.load(model2_path, map_location='cpu'))\n",
        "\n",
        "# fold3 model\n",
        "model3 = VGG16(NUM_CLS).to(DEVICE)\n",
        "model3.load_state_dict(torch.load(model3_path, map_location='cpu'))\n",
        "\n",
        "# fold4 model\n",
        "model4 = VGG16(NUM_CLS).to(DEVICE)\n",
        "model4.load_state_dict(torch.load(model4_path, map_location='cpu'))\n",
        "\n",
        "# fold5 model\n",
        "model5 = VGG16(NUM_CLS).to(DEVICE)\n",
        "model5.load_state_dict(torch.load(model5_path, map_location='cpu'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBF6VDGG_gsi",
        "outputId": "477d88b4-cd81-4fd8-f2de-77e640dcd2db"
      },
      "id": "UBF6VDGG_gsi",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fda1c64",
      "metadata": {
        "id": "8fda1c64"
      },
      "source": [
        "### define socoring funtion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "a49fe293",
      "metadata": {
        "id": "a49fe293"
      },
      "outputs": [],
      "source": [
        "# 평가 함수 정의\n",
        "def get_clf_eval(y_actual, y_pred):\n",
        "    accuracy = accuracy_score(y_actual, y_pred)\n",
        "    precision = precision_score(y_actual, y_pred)\n",
        "    recall = recall_score(y_actual, y_pred)\n",
        "    PR_AUC = average_precision_score(y_actual, y_pred)\n",
        "    AUC = roc_auc_score(y_actual, y_pred)\n",
        "    F1 = f1_score(y_actual, y_pred)\n",
        "    print(f'\\n전체 {len(y_actual)}개 validation data 중 양성(1) data {sum(y_actual)}개')\n",
        "    print('정확도: {:.4f}'.format(accuracy))\n",
        "    print('정밀도: {:.4f}'.format(precision))\n",
        "    print('재현율: {:.4f}'.format(recall))\n",
        "    print('AUC: {:.4f}'.format(AUC))\n",
        "    print('F1: {:.4f}'.format(F1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cheak CV score"
      ],
      "metadata": {
        "id": "dXU6LFdnrbxG"
      },
      "id": "dXU6LFdnrbxG"
    },
    {
      "cell_type": "code",
      "source": [
        "for fold, (_, val_idx) in enumerate(kfold.split(range(646))):\n",
        "    print(f'============================{fold+1}th fold============================')\n",
        "    validation_dataset = CustomDataset(data_dir=DATA_DIR, idx=val_idx, input_shape=INPUT_SHAPE)\n",
        "    validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    validation_actual = []\n",
        "    validation_pred_lst = []\n",
        "\n",
        "    if fold == 0:\n",
        "        model1.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch_index, (img, label, _) in tqdm(enumerate(validation_dataloader)):\n",
        "                img = img.to(DEVICE)\n",
        "                pred = model1(img)\n",
        "                validation_actual += (list(label.numpy()))\n",
        "                validation_pred_lst.extend(pred.argmax(dim=1).tolist())\n",
        "            get_clf_eval(validation_actual, validation_pred_lst)\n",
        "    \n",
        "    elif fold == 1:\n",
        "        model2.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch_index, (img, label, _) in tqdm(enumerate(validation_dataloader)):\n",
        "                img = img.to(DEVICE)\n",
        "                pred = model2(img)\n",
        "                validation_actual += (list(label.numpy()))\n",
        "                validation_pred_lst.extend(pred.argmax(dim=1).tolist())\n",
        "            get_clf_eval(validation_actual, validation_pred_lst)\n",
        "    \n",
        "    elif fold == 2:\n",
        "        model3.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch_index, (img, label, _) in tqdm(enumerate(validation_dataloader)):\n",
        "                img = img.to(DEVICE)\n",
        "                pred = model3(img)\n",
        "                validation_actual += (list(label.numpy()))\n",
        "                validation_pred_lst.extend(pred.argmax(dim=1).tolist())\n",
        "            get_clf_eval(validation_actual, validation_pred_lst)\n",
        "\n",
        "    elif fold == 3:\n",
        "        model4.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch_index, (img, label, _) in tqdm(enumerate(validation_dataloader)):\n",
        "                img = img.to(DEVICE)\n",
        "                pred = model4(img)\n",
        "                validation_actual += (list(label.numpy()))\n",
        "                validation_pred_lst.extend(pred.argmax(dim=1).tolist())\n",
        "            get_clf_eval(validation_actual, validation_pred_lst)\n",
        "\n",
        "    elif fold == 4:\n",
        "        model5.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch_index, (img, label, _) in tqdm(enumerate(validation_dataloader)):\n",
        "                img = img.to(DEVICE)\n",
        "                pred = model5(img)\n",
        "                validation_actual += (list(label.numpy()))\n",
        "                validation_pred_lst.extend(pred.argmax(dim=1).tolist())\n",
        "            get_clf_eval(validation_actual, validation_pred_lst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxyx1wm5FwR5",
        "outputId": "ee5240b1-3288-48a3-89c6-68f859bc5ad6"
      },
      "id": "Qxyx1wm5FwR5",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================1th fold============================\n",
            "Loading dataset..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8it [00:04,  1.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "전체 130개 validation data 중 양성(1) data 62개\n",
            "정확도: 0.8385\n",
            "정밀도: 0.8361\n",
            "재현율: 0.8226\n",
            "AUC: 0.8378\n",
            "F1: 0.8293\n",
            "============================2th fold============================\n",
            "Loading dataset..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8it [00:04,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "전체 129개 validation data 중 양성(1) data 52개\n",
            "정확도: 0.7907\n",
            "정밀도: 0.7119\n",
            "재현율: 0.8077\n",
            "AUC: 0.7935\n",
            "F1: 0.7568\n",
            "============================3th fold============================\n",
            "Loading dataset..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8it [00:04,  1.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "전체 129개 validation data 중 양성(1) data 63개\n",
            "정확도: 0.8760\n",
            "정밀도: 0.8406\n",
            "재현율: 0.9206\n",
            "AUC: 0.8770\n",
            "F1: 0.8788\n",
            "============================4th fold============================\n",
            "Loading dataset..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8it [00:04,  1.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "전체 129개 validation data 중 양성(1) data 66개\n",
            "정확도: 0.7597\n",
            "정밀도: 0.7778\n",
            "재현율: 0.7424\n",
            "AUC: 0.7601\n",
            "F1: 0.7597\n",
            "============================5th fold============================\n",
            "Loading dataset..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8it [00:04,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "전체 129개 validation data 중 양성(1) data 61개\n",
            "정확도: 0.7752\n",
            "정밀도: 0.7667\n",
            "재현율: 0.7541\n",
            "AUC: 0.7741\n",
            "F1: 0.7603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make submission"
      ],
      "metadata": {
        "id": "GwMdcjjPUZjz"
      },
      "id": "GwMdcjjPUZjz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define predict function"
      ],
      "metadata": {
        "id": "a3c06iQTqU_Q"
      },
      "id": "a3c06iQTqU_Q"
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측함수(soft voting)\n",
        "def predict(models, loader):\n",
        "    model1, model2, model3, model4, model5 = models\n",
        "\n",
        "    file_lst = []\n",
        "    pred_lst = []\n",
        "    prob_lst = []\n",
        "\n",
        "    model1.eval()\n",
        "    model2.eval()\n",
        "    model3.eval()\n",
        "    model4.eval()\n",
        "    model5.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_index, (img, _, file_num) in tqdm(enumerate(test_dataloader)):\n",
        "            img = img.to(DEVICE)\n",
        "        \n",
        "            prob1 = model1(img)\n",
        "            prob2 = model2(img)\n",
        "            prob3 = model3(img)\n",
        "            prob4 = model4(img)\n",
        "            prob5 = model5(img)\n",
        "\n",
        "            prob = (prob1 + prob2 + prob3 + prob4 + prob5) / 5\n",
        "            file_lst.extend(list(file_num))\n",
        "            pred_lst.extend(prob.argmax(dim=1).tolist())\n",
        "            prob_lst.extend(prob[:, 1].tolist())\n",
        "    \n",
        "    return pred_lst, prob_lst, file_lst"
      ],
      "metadata": {
        "id": "mdQSMWGw9AQ_"
      },
      "id": "mdQSMWGw9AQ_",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "75bbba92-b53c-499f-b5f9-b6ac3edde331",
      "metadata": {
        "id": "75bbba92-b53c-499f-b5f9-b6ac3edde331"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "ced90de9-50ec-4e18-9f42-5a1b493941a5",
      "metadata": {
        "id": "ced90de9-50ec-4e18-9f42-5a1b493941a5"
      },
      "outputs": [],
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, data_dir, input_shape):\n",
        "        self.data_dir = data_dir\n",
        "        self.input_shape = input_shape\n",
        "        \n",
        "        # Loading dataset\n",
        "        self.db = self.data_loader()\n",
        "        \n",
        "        # Transform function\n",
        "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    def data_loader(self):\n",
        "        print('Loading test dataset..')\n",
        "        if not os.path.isdir(self.data_dir):\n",
        "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
        "            sys.exit()\n",
        "        \n",
        "        db = pd.read_csv(os.path.join(self.data_dir, 'sample_submission.csv'))\n",
        "        return db\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.db)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        data = copy.deepcopy(self.db.loc[index])\n",
        "        \n",
        "        # Loading image\n",
        "        cvimg = cv2.imread(os.path.join(self.data_dir,'test',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
        "        if not isinstance(cvimg, np.ndarray):\n",
        "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
        "\n",
        "        # Preprocessing images\n",
        "        trans_image = self.transform(Image.fromarray(cvimg))\n",
        "\n",
        "\n",
        "        ####################################################################\n",
        "        ####                 리턴값에 -1 추가해줘야함                   ####\n",
        "        ####################################################################\n",
        "        return trans_image, -1, data['file_name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "cdd31a3d-08cd-48fc-87b0-137976d4d4bb",
      "metadata": {
        "id": "cdd31a3d-08cd-48fc-87b0-137976d4d4bb",
        "outputId": "fba655a2-c11d-4930-ff96-af921be19e2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test dataset..\n"
          ]
        }
      ],
      "source": [
        "# Load dataset & dataloader\n",
        "test_dataset = TestDataset(data_dir=DATA_DIR, input_shape=INPUT_SHAPE)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53efd72b-172d-4e34-a1dd-65ed8c745b58",
      "metadata": {
        "id": "53efd72b-172d-4e34-a1dd-65ed8c745b58"
      },
      "source": [
        "## 추론 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "16a090ea-bb34-4d3d-a127-b1190e8c416c",
      "metadata": {
        "id": "16a090ea-bb34-4d3d-a127-b1190e8c416c",
        "outputId": "02ca4750-4127-404d-e4ef-db9f46e61aab",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6it [00:08,  1.38s/it]\n"
          ]
        }
      ],
      "source": [
        "models = [model1, model2, model3, model4, model5]\n",
        "pred, prob, file_lst = predict(models, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "056169d1-64a8-4b81-8daf-722b029cf2b9",
      "metadata": {
        "id": "056169d1-64a8-4b81-8daf-722b029cf2b9"
      },
      "source": [
        "## 결과 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "f133cd86-b87b-4f8b-ae0e-c240655ae9ff",
      "metadata": {
        "id": "f133cd86-b87b-4f8b-ae0e-c240655ae9ff"
      },
      "outputs": [],
      "source": [
        "# prediction\n",
        "df = pd.DataFrame({'file_name':file_lst, 'COVID':pred})\n",
        "df.to_csv('prediction(VGG16_ensemble).csv', index=False)\n",
        "\n",
        "# probability\n",
        "df2 = pd.DataFrame({'file_name':file_lst, 'COVID':prob})\n",
        "df2.to_csv('probability(VGG16_ensemble).csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "vgg16_k-fold_ensemble.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}